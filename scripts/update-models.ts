#!/usr/bin/env ts-node
import * as fs from 'node:fs';
import * as https from 'node:https';
import * as path from 'node:path';
import { fileURLToPath } from 'node:url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

interface AIChatModelCard {
  contextWindowTokens: number;
  displayName: string;
  enabled?: boolean;
  id: string;
  maxOutput?: number;
  type: 'chat';
}

const LOBE_CHAT_CONFIG_URL =
  'https://raw.githubusercontent.com/lobehub/lobe-chat/refs/heads/next/packages/model-bank/src/aiModels/openai.ts';
const MODELS_FILE_PATH = path.join(__dirname, '../packages/common/models.ts');

/**
 * ä» URL è·å–å†…å®¹
 */
function fetchContent(url: string): Promise<string> {
  return new Promise((resolve, reject) => {
    https
      .get(url, (res) => {
        let data = '';
        res.on('data', (chunk) => {
          data += chunk;
        });
        res.on('end', () => {
          resolve(data);
        });
      })
      .on('error', (err) => {
        reject(err);
      });
  });
}

/**
 * è§£æ TypeScript é…ç½®æ–‡ä»¶å†…å®¹ï¼Œæå– openaiChatModels
 */
function parseOpenAIConfig(content: string): AIChatModelCard[] {
  const models: AIChatModelCard[] = [];

  // æŸ¥æ‰¾ openaiChatModels æ•°ç»„çš„å¼€å§‹
  const arrayStartMatch = content.match(
    /export const openaiChatModels:\s*AIChatModelCard\[]\s*=\s*\[/,
  );
  if (!arrayStartMatch) {
    throw new Error('æ— æ³•æ‰¾åˆ° openaiChatModels æ•°ç»„å®šä¹‰');
  }

  const arrayStartIndex = arrayStartMatch.index! + arrayStartMatch[0].length;

  // æ‰¾åˆ°æ•°ç»„çš„ç»“æŸä½ç½®ï¼ˆåŒ¹é…æ‹¬å·ï¼‰
  let bracketCount = 1;
  let currentIndex = arrayStartIndex;
  let arrayEndIndex = -1;

  while (currentIndex < content.length && bracketCount > 0) {
    const char = content[currentIndex];
    if (char === '[') bracketCount++;
    else if (char === ']') bracketCount--;

    if (bracketCount === 0) {
      arrayEndIndex = currentIndex;
      break;
    }
    currentIndex++;
  }

  if (arrayEndIndex === -1) {
    throw new Error('æ— æ³•æ‰¾åˆ° openaiChatModels æ•°ç»„çš„ç»“æŸä½ç½®');
  }

  // æå–æ•°ç»„å†…å®¹
  // eslint-disable-next-line unicorn/prefer-string-slice
  const arrayContent = content.substring(arrayStartIndex, arrayEndIndex);

  // ä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…æ¯ä¸ªæ¨¡å‹å¯¹è±¡
  const modelObjectRegex = /{\s*abilities:[\S\s]*?},(?=\s*{|\s*$)/g;
  const matches = arrayContent.match(modelObjectRegex);

  if (!matches) {
    console.log('æ•°ç»„å†…å®¹:', arrayContent.slice(0, 500) + '...');
    throw new Error('æ— æ³•æ‰¾åˆ°æ¨¡å‹é…ç½®å¯¹è±¡');
  }

  for (const modelStr of matches) {
    try {
      // æå– id
      const idMatch = modelStr.match(/id:\s*["'`]([^"'`]+)["'`]/);
      if (!idMatch) continue;
      const id = idMatch[1];

      // æå– displayName
      const displayNameMatch = modelStr.match(/displayName:\s*["'`]([^"'`]+)["'`]/);
      if (!displayNameMatch) continue;
      const displayName = displayNameMatch[1];

      // æå– contextWindowTokens
      const contextTokensMatch = modelStr.match(/contextWindowTokens:\s*([\d,_]+)/);
      if (!contextTokensMatch || !contextTokensMatch[1]) continue;
      // @ts-ignore
      const contextTokens = Number.parseInt(contextTokensMatch[1].replaceAll(/[,_]/g, ''));

      // æå– maxOutput (å¯é€‰)
      const maxOutputMatch = modelStr.match(/maxOutput:\s*([\d,_]+)/);
      const maxOutput = maxOutputMatch?.[1]
        ? Number.parseInt(maxOutputMatch[1].replaceAll(/[,_]/g, ''))
        : undefined;

      // æå– enabled (å¯é€‰ï¼Œé»˜è®¤ä¸º true)
      const enabledMatch = modelStr.match(/enabled:\s*(true|false)/);
      const enabled = enabledMatch ? enabledMatch[1] === 'true' : true;

      // ç¡®ä¿å¿…éœ€çš„å­—æ®µä¸ä¸º undefined
      if (!displayName || !id) continue;

      models.push({
        contextWindowTokens: contextTokens,
        displayName,
        enabled,
        id,
        maxOutput,
        type: 'chat',
      });
    } catch (error) {
      console.warn(`è§£ææ¨¡å‹å¯¹è±¡æ—¶å‡ºé”™: ${error}`);
      continue;
    }
  }

  return models;
}

/**
 * å°†æ¨¡å‹ ID è½¬æ¢ä¸ºæšä¸¾åç§°
 */
function modelIdToEnumName(id: string): string {
  return id.toUpperCase().replaceAll('-', '_').replaceAll('.', '_').replaceAll('+', '_PLUS');
}

/**
 * ç”Ÿæˆæ–°çš„ models.ts æ–‡ä»¶å†…å®¹
 */
function generateModelsFile(models: AIChatModelCard[]): string {
  const header = `// refs: https://github.com/lobehub/lobe-chat/blob/main/src/config/modelProviders/openai.ts
// Auto-generated file. Do not edit manually.
// Last updated: ${new Date().toISOString()}

`;

  // ç”Ÿæˆæšä¸¾
  const enumEntries = models
    .filter((model) => model.enabled !== false)
    .map((model) => {
      const enumName = modelIdToEnumName(model.id);
      return `  /**
   * ${model.displayName}
   */
  ${enumName} = '${model.id}',`;
    })
    .join('\n');

  const enumSection = `export enum LanguageModel {
${enumEntries}
}

`;

  // ç”Ÿæˆ token æ˜ å°„
  const tokenEntries = models
    .filter((model) => model.enabled !== false)
    .map((model) => {
      const enumName = modelIdToEnumName(model.id);
      return `  [LanguageModel.${enumName}]: ${model.contextWindowTokens.toLocaleString().replaceAll(',', '_')},`;
    })
    .join('\n');

  const tokenSection = `export const ModelTokens: Record<LanguageModel, number> = {
${tokenEntries}
};

`;

  // è®¾ç½®é»˜è®¤æ¨¡å‹ï¼ˆé€‰æ‹©æœ€æ–°çš„ mini æ¨¡å‹ï¼‰
  const defaultModelCandidate =
    models.find((m) => m.id === 'o4-mini') ||
    models.find((m) => m.id === 'gpt-4.1-mini') ||
    models.find((m) => m.id === 'gpt-4o-mini') ||
    models.find((m) => m.id === 'o3-mini') ||
    models[0];

  if (!defaultModelCandidate) {
    throw new Error('æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„é»˜è®¤æ¨¡å‹');
  }

  const defaultModelEnum = modelIdToEnumName(defaultModelCandidate.id);
  const defaultSection = `export const defaultModel = LanguageModel.${defaultModelEnum};
`;

  return header + enumSection + tokenSection + defaultSection;
}

/**
 * ä¸»å‡½æ•°
 */
async function main() {
  try {
    console.log('ğŸš€ å¼€å§‹æ›´æ–°æ¨¡å‹é…ç½®...');

    // 1. è·å–è¿œç¨‹é…ç½®
    console.log('ğŸ“¥ è·å– LobeChat OpenAI é…ç½®...');
    const content = await fetchContent(LOBE_CHAT_CONFIG_URL);

    // 2. è§£æé…ç½®
    console.log('ğŸ” è§£ææ¨¡å‹é…ç½®...');
    const models = parseOpenAIConfig(content);
    console.log(`âœ… æ‰¾åˆ° ${models.length} ä¸ªèŠå¤©æ¨¡å‹`);

    // 3. ç”Ÿæˆæ–°æ–‡ä»¶å†…å®¹
    console.log('ğŸ“ ç”Ÿæˆæ–°çš„ models.ts æ–‡ä»¶...');
    const newContent = generateModelsFile(models);

    // 4. å†™å…¥æ–‡ä»¶
    console.log('ğŸ’¾ å†™å…¥æ–‡ä»¶...');
    fs.writeFileSync(MODELS_FILE_PATH, newContent, 'utf8');

    console.log('âœ… æ¨¡å‹é…ç½®æ›´æ–°å®Œæˆï¼');
    console.log(`ğŸ“ æ–‡ä»¶ä½ç½®: ${MODELS_FILE_PATH}`);

    // æ˜¾ç¤ºæ›´æ–°çš„æ¨¡å‹åˆ—è¡¨
    console.log('\nğŸ“‹ æ›´æ–°çš„æ¨¡å‹åˆ—è¡¨:');
    for (const model of models.filter((model) => model.enabled !== false)) {
      console.log(`  - ${model.displayName} (${model.id})`);
    }
  } catch (error) {
    console.error('âŒ æ›´æ–°å¤±è´¥:', error);
    process.exit(1);
  }
}

const run = async () => {
  if (require.main === module) {
    await main();
  }
};

// è¿è¡Œè„šæœ¬
run();
